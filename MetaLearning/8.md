# Fast Context Adaptation via Meta-Learning

* **Author**:Luisa Zintgraf 、 Kyriacos Shiarlis 、 Vitaly Kurin 、 Katja Hofmann 、 Shimon Whiteson 
* **Abstract**: We propose CAVIA for meta-learning, a simple extension to MAML that is less prone to metaoverfitting, easier to parallelise, and more interpretable. CAVIA partitions the model parameters into two parts: context parameters that serve as additional input to the model and are adapted
  on individual tasks, and shared parameters that are meta-trained and shared across tasks. At test time, only the context parameters are updated, leading to a low-dimensional task representation. We show empirically that CAVIA outperforms MAML for regression, classification, and reinforcement learning. Our experiments also highlight weaknesses in current benchmarks, in that the amount of adaptation needed in some cases is small.
* **Summary**: CAVIA is a meta-learning approach that separates the model into task-specific context parameters and parameters that are
  shared across tasks. We demonstrated experimentally that CAVIA is robust to the inner loop learning rate and yields task embeddings in the context parameters. CAVIA outperforms MAML on challenging regression, classification, and reinforcement learning problems, while adapting fewer parameters at test time and being less prone to overfitting. We are interested in extending our experimental evaluation to settings with multi-modal task distributions, as well as settings where more generalisation beyond task identification is necessary at test time. One possible approach here is
  to combine CAVIA with MAML-style updates in the future: i.e., having two separate inner loops (producing i and i), and one outer loop. We are  interested in extending CAVIA to more challenging RL problems and exploring its role in allowing for smart exploration in order to identify the task at hand, for example building on the work of Gupta et al. (2018) who use probabilistic context variables, or Stadie et al. (2018), who propose E-MAML for RL problems, an extension for MAML which accounts for the effect of the initial sampling distribution (policy) before the inner-loop update.
* **Keywords**: Few-shot learning, Meta-learning
* **code**：https://github.com/lmzintgraf/cavia.
* **dataset**：CelebA

